{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOub/4Yg9ksf5SIyIWarT0/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SriJanakiram/talentscout_ai_chatbot/blob/main/Hiring_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "TvS78FqM4H_a",
        "outputId": "c9fed3c7-5594-4356-a023-e8564ed6a2cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/chat_interface.py:339: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  self.chatbot = Chatbot(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://3da4982d1baa87970e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://3da4982d1baa87970e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import google.generativeai as genai\n",
        "import re\n",
        "import os\n",
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "csv_file_path = \"/content/talentscout_candidates.csv\"\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBi1rQE8TlT1bnc90Mg_09TIIo5YvqnoAA\"\n",
        "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "    model_name=\"gemini-1.5-flash\",\n",
        "    generation_config={\n",
        "        \"temperature\": 1,\n",
        "        \"top_p\": 0.95,\n",
        "        \"top_k\": 64,\n",
        "        \"max_output_tokens\": 8192,\n",
        "        \"response_mime_type\": \"text/plain\",\n",
        "    },\n",
        ")\n",
        "\n",
        "chat_session = model.start_chat()\n",
        "\n",
        "global_state = {\n",
        "    \"stage\": \"greeting\",\n",
        "    \"candidate_info\": {},\n",
        "    \"tech_questions\": \"\"\n",
        "}\n",
        "\n",
        "exit_keywords = [\"exit\", \"quit\", \"bye\", \"cancel\", \"stop\", \"end\"]\n",
        "\n",
        "fallback_responses = [\n",
        "    \"I'm sorry, could you please rephrase that?\",\n",
        "    \"I didn't quite catch that. Can you clarify?\",\n",
        "    \"Hmm, that doesn't look like something I expected. Could you try again?\",\n",
        "    \"Oops, I wasn't able to understand. Let's try once more.\"\n",
        "]\n",
        "\n",
        "def extract_field(user_input, field):\n",
        "    patterns = {\n",
        "        'name': r\"(my name is|i am|this is)\\s+(.*)\",\n",
        "        'email': r\"(my email is|email:)\\s*([\\w\\.-]+@[\\w\\.-]+)\",\n",
        "        'phone': r\"(my phone is|phone:)\\s*(\\+?\\d[\\d\\s\\-]{7,})\",\n",
        "        'experience': r\"(i have|experience:)\\s*(\\d+)\\s*(years|yrs)?\",\n",
        "        'position': r\"(i want to apply for|desired position is|position:)\\s*(.+)\",\n",
        "        'location': r\"(i live in|location:)\\s*(.+)\",\n",
        "        'tech_stack': r\"(i work with|my tech stack is|i use)\\s+(.+)\",\n",
        "    }\n",
        "    pattern = patterns.get(field)\n",
        "    if pattern:\n",
        "        match = re.search(pattern, user_input, re.IGNORECASE)\n",
        "        if match:\n",
        "            return match.group(2).strip()\n",
        "    return None\n",
        "\n",
        "def save_candidate_data(info):\n",
        "    row = [\n",
        "        info.get(\"name\"), info.get(\"email\"), info.get(\"phone\"),\n",
        "        info.get(\"experience\"), info.get(\"position\"),\n",
        "        info.get(\"location\"), info.get(\"tech_stack\")\n",
        "    ]\n",
        "    try:\n",
        "        df = pd.DataFrame([row], columns=[\"Name\", \"Email\", \"Phone\", \"Experience\", \"Position\", \"Location\", \"Tech Stack\"])\n",
        "        if os.path.exists(csv_file_path):\n",
        "            df.to_csv(csv_file_path, mode='a', header=False, index=False)\n",
        "        else:\n",
        "            df.to_csv(csv_file_path, mode='w', header=True, index=False)\n",
        "        print(f\"‚úÖ Candidate data saved to {csv_file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùó Error saving data: {e}\")\n",
        "\n",
        "def generate_technical_questions(tech_stack):\n",
        "    prompt = (\n",
        "        f\"You are a technical interviewer. For each technology in this list: {tech_stack}, generate exactly 3 technical interview questions. \"\n",
        "        f\"Format the questions clearly under each tech title like:\\n\\n\"\n",
        "        f\"Technology: Python\\n1. ...\\n2. ...\\n3. ...\\n\\n\"\n",
        "        f\"Now proceed with: {tech_stack}\"\n",
        "    )\n",
        "    try:\n",
        "        print(f\"Generating questions for tech stack: {tech_stack}\")\n",
        "        response = chat_session.send_message(prompt)\n",
        "        print(f\"Gemini response: {response}\")\n",
        "        return response.text.strip() if response and hasattr(response, 'text') else \"‚ùó Sorry, no questions generated.\"\n",
        "    except Exception as e:\n",
        "        print(f\"Gemini API Exception: {str(e)}\")\n",
        "        return f\"‚ùó Failed to generate questions due to: {str(e)}\"\n",
        "\n",
        "\n",
        "def chatbot(user_input, history):\n",
        "    user_input_lower = user_input.strip().lower()\n",
        "    if any(kw in user_input_lower for kw in exit_keywords):\n",
        "        global_state[\"stage\"] = \"end_conversation\"\n",
        "        return \"We will notice you. Thank you! üëã\"\n",
        "\n",
        "    stage = global_state[\"stage\"]\n",
        "    info = global_state[\"candidate_info\"]\n",
        "\n",
        "    def fallback():\n",
        "        import random\n",
        "        return random.choice(fallback_responses)\n",
        "\n",
        "    if stage == \"greeting\":\n",
        "        global_state[\"stage\"] = \"collect_name\"\n",
        "        return \"üëã Hello! I‚Äôm TalentScout‚Äôs Hiring Assistant. What is your full name?\"\n",
        "\n",
        "    elif stage == \"collect_name\":\n",
        "        result = extract_field(user_input, 'name')\n",
        "        if not result:\n",
        "            if len(user_input.split()) <= 4 and (user_input.replace(\" \", \"\").isalpha()):\n",
        "                result = user_input.strip()\n",
        "        if result:\n",
        "            info['name'] = result\n",
        "            global_state[\"stage\"] = \"collect_email\"\n",
        "            return f\"Thanks, {info['name']}! What's your email address?\"\n",
        "        return fallback()\n",
        "\n",
        "    elif stage == \"collect_email\":\n",
        "        result = extract_field(user_input, 'email')\n",
        "        if not result:\n",
        "            email_match = re.search(r\"[\\w\\.-]+@[\\w\\.-]+\", user_input)\n",
        "            if email_match:\n",
        "                result = email_match.group(0)\n",
        "        if result:\n",
        "            info['email'] = result\n",
        "            global_state[\"stage\"] = \"collect_phone\"\n",
        "            return \"Got it. Could you also share your phone number?\"\n",
        "        return fallback()\n",
        "\n",
        "    elif stage == \"collect_phone\":\n",
        "        result = extract_field(user_input, 'phone')\n",
        "        if not result:\n",
        "            phone_match = re.search(r\"\\+?\\d[\\d\\s\\-]{7,}\", user_input)\n",
        "            if phone_match:\n",
        "                result = phone_match.group(0)\n",
        "        if result:\n",
        "            info['phone'] = result\n",
        "            global_state[\"stage\"] = \"collect_experience\"\n",
        "            return \"Thanks. How many years of experience do you have?\"\n",
        "        return fallback()\n",
        "\n",
        "    elif stage == \"collect_experience\":\n",
        "        result = extract_field(user_input, 'experience')\n",
        "        if not result:\n",
        "            experience_match = re.search(r\"\\d+\", user_input)\n",
        "            if experience_match:\n",
        "                result = experience_match.group(0)\n",
        "        if result:\n",
        "            info['experience'] = result\n",
        "            global_state[\"stage\"] = \"collect_position\"\n",
        "            return \"Great! What position are you applying for?\"\n",
        "        return fallback()\n",
        "\n",
        "    elif stage == \"collect_position\":\n",
        "        result = extract_field(user_input, 'position')\n",
        "        if not result:\n",
        "            if len(user_input.split()) <= 6:\n",
        "                result = user_input.strip()\n",
        "        if result:\n",
        "            info['position'] = result\n",
        "            global_state[\"stage\"] = \"collect_location\"\n",
        "            return \"Noted. Where are you currently located?\"\n",
        "        return fallback()\n",
        "\n",
        "    elif stage == \"collect_location\":\n",
        "        result = extract_field(user_input, 'location')\n",
        "        if not result:\n",
        "            if len(user_input.split()) <= 6:\n",
        "                result = user_input.strip()\n",
        "        if result:\n",
        "            info['location'] = result\n",
        "            global_state[\"stage\"] = \"collect_tech_stack\"\n",
        "            return \"Thanks! Now, please list your tech stack (e.g., Python, React, MongoDB).\"\n",
        "        return fallback()\n",
        "\n",
        "    elif stage == \"collect_tech_stack\":\n",
        "        result = extract_field(user_input, 'tech_stack')\n",
        "        if not result:\n",
        "            if len(user_input.split(\",\")) >= 1:\n",
        "                result = user_input.strip()\n",
        "        if result:\n",
        "            info['tech_stack'] = result\n",
        "            global_state[\"stage\"] = \"generate_questions\"\n",
        "            questions = generate_technical_questions(info['tech_stack'])\n",
        "            global_state['tech_questions'] = questions\n",
        "            save_candidate_data(info)\n",
        "            global_state[\"stage\"] = \"end_conversation\"\n",
        "            return f\"Thanks! Based on your stack, here are your technical questions:\\n\\n{questions}\"\n",
        "        return fallback()\n",
        "\n",
        "    elif stage == \"end_conversation\":\n",
        "        return \"That's all I need for now. We'll get back to you soon. Have a great day! üëã\"\n",
        "\n",
        "    else:\n",
        "        return fallback()\n",
        "\n",
        "chat_interface = gr.ChatInterface(fn=chatbot, title=\"TalentScout Hiring Assistant\")\n",
        "chat_interface.launch(share=True, debug=True)\n"
      ]
    }
  ]
}